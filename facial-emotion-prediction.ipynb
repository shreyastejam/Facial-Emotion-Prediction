{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Group 17\n# Facial Emotion Prediction","metadata":{}},{"cell_type":"markdown","source":"## Problem Definition","metadata":{}},{"cell_type":"markdown","source":"To predict the emotion a person is experiencing from a picture of their face. \n\n**Task (T)**: Predict the emotion of the person from an image of their face. \n\n**Experience (E)**: Images of faces from the datasets. \n\n**Performance (P)**: How often the model will correctly predict human emotion from images.","metadata":{}},{"cell_type":"markdown","source":"## Datasets","metadata":{}},{"cell_type":"markdown","source":"### 1. Google facial expression comparison dataset\n\nThis dataset is a large-scale facial expression dataset consisting of face image triplets along with human annotations that specify which two faces in each triplet form the most similar pair in terms of facial expression. Each triplet in this dataset was annotated by six or more human raters. This dataset is quite different from existing expression datasets that focus mainly on discrete emotion classification or action unit detection. \n\n[Link](https://research.google/tools/datasets/google-facial-expression/)","metadata":{}},{"cell_type":"markdown","source":"### 2. FER-2013 Learn facial Expressions from an image - Kaggle\n\n* The data consists of 48x48 pixel grayscale images of faces. The faces havebeen automatically registered so that the face is more or less centered and occupies about the same amount of space in each image.\n* Facial expressions are divided into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples.\n\n[Link](https://www.kaggle.com/msambare/fer2013)","metadata":{}},{"cell_type":"markdown","source":"### 3. The Olivetti faces dataset\n* This dataset contains a set of face images taken between April 1992 and April 1994 at AT&T Laboratories Cambridge. The sklearn.datasets.fetch_olivetti_facesfunction is the data fetching / caching function that downloads the data archive from AT&T.\n* There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). Allthe images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).\n* This Dataset is intended for all users as part of scikit learn python library\n\n[Link](https://www.kaggle.com/msambare/fer2013)","metadata":{}},{"cell_type":"markdown","source":"### Importing the necessary Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:21.994189Z","iopub.execute_input":"2022-07-21T06:13:21.994583Z","iopub.status.idle":"2022-07-21T06:13:28.269352Z","shell.execute_reply.started":"2022-07-21T06:13:21.994495Z","shell.execute_reply":"2022-07-21T06:13:28.268587Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Exploring the dataset","metadata":{}},{"cell_type":"code","source":"print(os.listdir('/kaggle/input/fer2013'))","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:28.270816Z","iopub.execute_input":"2022-07-21T06:13:28.271515Z","iopub.status.idle":"2022-07-21T06:13:28.281413Z","shell.execute_reply.started":"2022-07-21T06:13:28.271470Z","shell.execute_reply":"2022-07-21T06:13:28.280123Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/fer2013/train'\nval_path = '/kaggle/input/fer2013/test'","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:28.282920Z","iopub.execute_input":"2022-07-21T06:13:28.283257Z","iopub.status.idle":"2022-07-21T06:13:28.288882Z","shell.execute_reply.started":"2022-07-21T06:13:28.283193Z","shell.execute_reply":"2022-07-21T06:13:28.288074Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Importing TensorFlow libraries\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras import Sequential\nfrom tensorflow import keras\nfrom sklearn.model_selection import KFold","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:28.292944Z","iopub.execute_input":"2022-07-21T06:13:28.293731Z","iopub.status.idle":"2022-07-21T06:13:28.989844Z","shell.execute_reply.started":"2022-07-21T06:13:28.293673Z","shell.execute_reply":"2022-07-21T06:13:28.989093Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\nExplain the pre-processing done on your Dataset to make it suitable for applying machine learning algorithms.\n\nWe are getting the directories with images and storing the labels of the respective directories as lists. Then we rescale all images to a uniform size (<b>Normalization</b>) which allows all images to contribute equally to the total loss rather than when other images have high and low pixels ranges give strong and weak loss, respectively. Since high pixel images require a low learning rate and low pixel images high learning rate, re-scaling helps provide a standard learning rate for all images.\n\nWe also converted the colored images to Grayscale to reduce computation complexity (<b>Greyscale Conversion</b>). \n\nWe have also used rescaling to augment data from the existing data (<b>Data Augumentation with rescaling</b>).","metadata":{}},{"cell_type":"code","source":"emotion_labels = sorted(os.listdir(train_path))\nprint(emotion_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:28.991019Z","iopub.execute_input":"2022-07-21T06:13:28.991388Z","iopub.status.idle":"2022-07-21T06:13:28.999775Z","shell.execute_reply.started":"2022-07-21T06:13:28.991350Z","shell.execute_reply":"2022-07-21T06:13:28.998951Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntarget_size = (48,48)\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen   = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical',\n        shuffle=True)\n\nval_generator = val_datagen.flow_from_directory(\n        val_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:29.000989Z","iopub.execute_input":"2022-07-21T06:13:29.001915Z","iopub.status.idle":"2022-07-21T06:13:55.315062Z","shell.execute_reply.started":"2022-07-21T06:13:29.001872Z","shell.execute_reply":"2022-07-21T06:13:55.314120Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data Summarization","metadata":{}},{"cell_type":"markdown","source":"### Dimensions of the Dataset","metadata":{}},{"cell_type":"code","source":"input_shape = (48,48,1) # img_rows, img_colums, color_channels\nnum_classes = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:55.316457Z","iopub.execute_input":"2022-07-21T06:13:55.316686Z","iopub.status.idle":"2022-07-21T06:13:55.320520Z","shell.execute_reply.started":"2022-07-21T06:13:55.316659Z","shell.execute_reply":"2022-07-21T06:13:55.319780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Statistical Summary of all attributes","metadata":{}},{"cell_type":"code","source":"print(os.listdir('/kaggle/input/fer2013/train'))","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:55.321578Z","iopub.execute_input":"2022-07-21T06:13:55.321788Z","iopub.status.idle":"2022-07-21T06:13:55.336564Z","shell.execute_reply.started":"2022-07-21T06:13:55.321764Z","shell.execute_reply":"2022-07-21T06:13:55.335770Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Breakdown of all data class variable","metadata":{}},{"cell_type":"code","source":"def plot_images(img_dir, top=10):\n    all_img_dirs = os.listdir(img_dir)\n    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n  \n    plt.figure(figsize=(12, 12))\n  \n    for idx, img_path in enumerate(img_files):\n        plt.subplot(5, 5, idx+1)\n        img = plt.imread(img_path)\n        plt.tight_layout()         \n        plt.imshow(img, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:55.338044Z","iopub.execute_input":"2022-07-21T06:13:55.338818Z","iopub.status.idle":"2022-07-21T06:13:55.346929Z","shell.execute_reply.started":"2022-07-21T06:13:55.338787Z","shell.execute_reply":"2022-07-21T06:13:55.346099Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print('Angry: ')\nprint()\nplot_images(train_path+'/angry')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:55.349100Z","iopub.execute_input":"2022-07-21T06:13:55.349805Z","iopub.status.idle":"2022-07-21T06:13:56.301097Z","shell.execute_reply.started":"2022-07-21T06:13:55.349776Z","shell.execute_reply":"2022-07-21T06:13:56.300350Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print('Disgust: ')\nprint()\nplot_images(train_path+'/disgust')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:56.302191Z","iopub.execute_input":"2022-07-21T06:13:56.302506Z","iopub.status.idle":"2022-07-21T06:13:57.097621Z","shell.execute_reply.started":"2022-07-21T06:13:56.302469Z","shell.execute_reply":"2022-07-21T06:13:57.096690Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print('Fear: ')\nprint()\nplot_images(train_path+'/fear')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:57.099132Z","iopub.execute_input":"2022-07-21T06:13:57.099443Z","iopub.status.idle":"2022-07-21T06:13:57.884715Z","shell.execute_reply.started":"2022-07-21T06:13:57.099408Z","shell.execute_reply":"2022-07-21T06:13:57.883944Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('Happy: ')\nprint()\nplot_images(train_path+'/happy')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:57.886462Z","iopub.execute_input":"2022-07-21T06:13:57.887225Z","iopub.status.idle":"2022-07-21T06:13:58.681706Z","shell.execute_reply.started":"2022-07-21T06:13:57.887166Z","shell.execute_reply":"2022-07-21T06:13:58.681183Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print('Neutral: ')\nprint()\nplot_images(train_path+'/neutral')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:58.682556Z","iopub.execute_input":"2022-07-21T06:13:58.683148Z","iopub.status.idle":"2022-07-21T06:13:59.472815Z","shell.execute_reply.started":"2022-07-21T06:13:58.683118Z","shell.execute_reply":"2022-07-21T06:13:59.471604Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print('Sad: ')\nprint()\nplot_images(train_path+'/sad')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:13:59.473985Z","iopub.execute_input":"2022-07-21T06:13:59.474236Z","iopub.status.idle":"2022-07-21T06:14:00.271739Z","shell.execute_reply.started":"2022-07-21T06:13:59.474186Z","shell.execute_reply":"2022-07-21T06:14:00.270935Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print('Surprise: ')\nprint()\nplot_images(train_path+'/surprise')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:00.273141Z","iopub.execute_input":"2022-07-21T06:14:00.273613Z","iopub.status.idle":"2022-07-21T06:14:01.060309Z","shell.execute_reply.started":"2022-07-21T06:14:00.273573Z","shell.execute_reply":"2022-07-21T06:14:01.059643Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"emotions = os.listdir('/kaggle/input/fer2013/train')\nfor emotion in emotions:\n    count = len(os.listdir(f'/kaggle/input/fer2013/train/{emotion}'))\n    print(f'{emotion} faces={count}')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.061349Z","iopub.execute_input":"2022-07-21T06:14:01.061649Z","iopub.status.idle":"2022-07-21T06:14:01.082733Z","shell.execute_reply.started":"2022-07-21T06:14:01.061624Z","shell.execute_reply":"2022-07-21T06:14:01.081445Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"emotions = os.listdir('/kaggle/input/fer2013/test')\nfor emotion in emotions:\n    count = len(os.listdir(f'/kaggle/input/fer2013/test/{emotion}'))\n    print(f'{emotion} faces={count}')","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.084501Z","iopub.execute_input":"2022-07-21T06:14:01.084807Z","iopub.status.idle":"2022-07-21T06:14:01.105005Z","shell.execute_reply.started":"2022-07-21T06:14:01.084765Z","shell.execute_reply":"2022-07-21T06:14:01.104373Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"emotions = os.listdir('/kaggle/input/fer2013/train')\nvalues = [len(os.listdir(f'/kaggle/input/fer2013/train/{emotion}')) for emotion in emotions]\nfig = plt.figure(figsize = (10, 5))\n\n# creating the bar plot\nplt.bar(emotions, values, color ='grey',\n        width = 0.4)\n\nplt.xlabel(\"Emotions\")\nplt.ylabel(\"No. of images\")\nplt.title(\"Train dataset overview\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.106127Z","iopub.execute_input":"2022-07-21T06:14:01.106792Z","iopub.status.idle":"2022-07-21T06:14:01.337721Z","shell.execute_reply.started":"2022-07-21T06:14:01.106747Z","shell.execute_reply":"2022-07-21T06:14:01.336806Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"emotions = os.listdir('/kaggle/input/fer2013/test')\nvalues = [len(os.listdir(f'/kaggle/input/fer2013/test/{emotion}')) for emotion in emotions]\nfig = plt.figure(figsize = (10, 5))\n\n# creating the bar plot\nplt.bar(emotions, values, color ='grey',\n        width = 0.4)\n\nplt.xlabel(\"Emotions\")\nplt.ylabel(\"No. of images\")\nplt.title(\"Test dataset overview\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.338666Z","iopub.execute_input":"2022-07-21T06:14:01.338863Z","iopub.status.idle":"2022-07-21T06:14:01.544127Z","shell.execute_reply.started":"2022-07-21T06:14:01.338839Z","shell.execute_reply":"2022-07-21T06:14:01.543312Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Python Packages\n\n1. Numpy\n2. Pandas\n3. Matplotlib\n4. OS\n5. Tensorflow\n6. Sklearn","metadata":{}},{"cell_type":"markdown","source":"# Supervised Learning","metadata":{}},{"cell_type":"markdown","source":"## 1. Convolutional Neural Network (CNN)\n\nConvolutional neural networks (CNN) is a special architecture of artificial neural networks. CNNs uses some of its features of visual cortex and have therefore achieved state of the art results in computer vision tasks.\n\nConvolutional neural networks are comprised of two very simple elements, namely convolutional layers and pooling layers.\nAlthough simple, there are near-infinite ways to arrange these layers for a given computer vision problem.\nThe elements of a convolutional neural network, such as convolutional and pooling layers, are relatively straightforward to understand.\nThe challenging part of using convolutional neural networks in practice is how to design model architectures that best use these simple elements.","metadata":{}},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Conv2D(16,(5,5),padding='valid',input_shape = input_shape)) # Convolutional layers\nmodel.add(layers.Activation('relu')) # activation functions\nmodel.add(layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid')) # to reduce size of image\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Conv2D(32,(5,5),padding='valid'))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'))\nmodel.add(layers.Dropout(0.6))\n\nmodel.add(layers.Conv2D(64,(5,5),padding='valid'))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.8))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(7)) # classification\n\nmodel.add(layers.Activation('softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.545293Z","iopub.execute_input":"2022-07-21T06:14:01.545903Z","iopub.status.idle":"2022-07-21T06:14:01.942827Z","shell.execute_reply.started":"2022-07-21T06:14:01.545864Z","shell.execute_reply":"2022-07-21T06:14:01.941879Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Compile Model\noptimizer = keras.optimizers.RMSprop(lr = 0.0001, decay = 1e-6)\nmodel.compile(loss = 'binary_crossentropy',optimizer = optimizer, metrics = ['accuracy',keras.metrics.Precision(), keras.metrics.Recall()])","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.944000Z","iopub.execute_input":"2022-07-21T06:14:01.944327Z","iopub.status.idle":"2022-07-21T06:14:01.967494Z","shell.execute_reply.started":"2022-07-21T06:14:01.944295Z","shell.execute_reply":"2022-07-21T06:14:01.966777Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model","metadata":{}},{"cell_type":"code","source":"num_epochs = 300\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VAL   = val_generator.n//val_generator.batch_size","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.968426Z","iopub.execute_input":"2022-07-21T06:14:01.968815Z","iopub.status.idle":"2022-07-21T06:14:01.972592Z","shell.execute_reply.started":"2022-07-21T06:14:01.968783Z","shell.execute_reply":"2022-07-21T06:14:01.972053Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train Model\nhistory = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, batch_size=batch_size, validation_data=val_generator, validation_steps=STEP_SIZE_VAL)\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-07-21T06:14:01.973513Z","iopub.execute_input":"2022-07-21T06:14:01.974193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### k-fold Cross Validation","metadata":{}},{"cell_type":"code","source":"# kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n# cvscores = []\n\n# for train_index, test_index in kfold.split(train_generator, val_generator):\n#     model = Sequential()\n#     model.add(layers.Conv2D(16,(5,5),padding='valid',input_shape = input_shape))\n#     model.add(layers.Activation('relu'))\n#     model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'))\n#     model.add(layers.Dropout(0.4))\n\n#     model.add(layers.Conv2D(32,(5,5),padding='valid'))\n#     model.add(layers.Activation('relu'))\n#     model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'))\n#     model.add(layers.Dropout(0.6))\n\n#     model.add(layers.Conv2D(64,(5,5),padding='valid'))\n#     model.add(layers.Activation('relu'))\n#     model.add(layers.Dropout(0.8))\n#     model.add(layers.Flatten())\n#     model.add(layers.Dense(7))\n\n#     model.add(layers.Activation('softmax'))\n    \n#     optimizer = keras.optimizers.RMSprop(lr = 0.0001, decay = 1e-6)\n#     model.compile(loss = 'binary_crossentropy',optimizer = optimizer, metrics = ['accuracy',keras.metrics.Precision(), keras.metrics.Recall()])\n    \n#     X_train, X_test = train_generator[train_index], train_generator[test_index]\n#     y_train, y_test = val_generator[train_index], val_generator[test_index]\n#     history = model.fit(X_train, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, batch_size=batch_size, validation_data=y_train, validation_steps=STEP_SIZE_VAL)\n    \n#     scores = model.evaluate(X[test], y[test], verbose=0)\n#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n#     cvscores.append(scores[1] * 100)\n\n# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model","metadata":{}},{"cell_type":"code","source":"models.save_model(model, 'CNN.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Model","metadata":{}},{"cell_type":"code","source":"cnn_score = model.evaluate_generator(val_generator, steps=STEP_SIZE_VAL) \nprint('Test loss: ', cnn_score[0])\nprint('Test accuracy: ', cnn_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show Training History","metadata":{}},{"cell_type":"code","source":"keys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Support Vector Machine (SVM)","metadata":{}},{"cell_type":"markdown","source":"It is a supervised machine learning algorithm used for both regression and classification problems.\nWhen used for classification purposes, it separates the classes using a linear boundary.\n\nGenerally, Support Vector Machines(SVM) is considered to be a classification approach but it can be employed in both types of classification and regression problems. It can easily handle multiple continuous and categorical variables. SVM constructs a hyperplane in multidimensional space to separate different classes. SVM generates optimal hyperplane in an iterative manner, which is used to minimize an error. The core idea of SVM is to find a maximum marginal hyperplane(MMH) that best divides the dataset into classes.","metadata":{}},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"code","source":"num_epochs = 200\nnumber_of_classes = 7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3, strides = 2,input_shape=input_shape))\nmodel.add(layers.MaxPool2D(pool_size=(2,2),strides = 2))\n\nmodel.add(layers.Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3))\nmodel.add(layers.MaxPool2D(pool_size=(2,2),strides = 2))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128,activation=\"relu\"))\n\n#Output layer\nmodel.add(layers.Dense(1,kernel_regularizer=regularizers.l2(0.01),activation = \"linear\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.add(layers.Dense(number_of_classes,kernel_regularizer = regularizers.l2(0.01),activation= \"softmax\"))\nmodel.compile(optimizer=\"adam\",loss=\"squared_hinge\", metrics = ['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(x=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, batch_size=batch_size, validation_data=val_generator, validation_steps=STEP_SIZE_VAL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model","metadata":{}},{"cell_type":"code","source":"models.save_model(model, 'SVM.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Model","metadata":{}},{"cell_type":"code","source":"svm_score = model.evaluate_generator(val_generator, steps=STEP_SIZE_VAL) \nprint('Test loss: ', svm_score[0])\nprint('Test accuracy: ', svm_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show Training History","metadata":{}},{"cell_type":"code","source":"keys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Artificial Neural Networks (ANN)\n\nANNs are implemented as a system of interconnected processing elements, called nodes, which are functionally analogous to biological neurons.The connections between different nodes have numerical values, called weights, and by altering these values in a systematic way, the network is eventually able to approximate the desired function.","metadata":{}},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"code","source":"model_ann = Sequential()\nmodel_ann.add(layers.Dense(16, input_shape=input_shape, activation='relu'))\nmodel_ann.add(layers.Dropout(0.4))\nmodel_ann.add(layers.Dense(32, activation='relu'))\nmodel_ann.add(layers.Dropout(0.6))\nmodel_ann.add(layers.Flatten())\nmodel_ann.add(layers.Dense(7, activation='softmax'))\n\nmodel_ann.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ann.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_ann.fit(x=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, batch_size=batch_size, validation_data=val_generator, validation_steps=STEP_SIZE_VAL)\nhistory","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model","metadata":{}},{"cell_type":"code","source":"models.save_model(model, 'ANN.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Model","metadata":{}},{"cell_type":"code","source":"ann_score = model.evaluate_generator(val_generator, steps=STEP_SIZE_VAL) \nprint('Test loss: ', ann_score[0])\nprint('Test accuracy: ', ann_score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show Training History","metadata":{}},{"cell_type":"code","source":"keys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparing accuracy to find best Model","metadata":{}},{"cell_type":"code","source":"# Accuracy of the different models\nnames = ['CNN', 'SVM', 'ANN']\ncompare_acc = [0.51, 0.7224, 0.4436]\n# compare_acc = [0.94, 0.23, 0.45]\nplt.figure(figsize=(20,6))\n\n\nplt.barh(names,compare_acc, color=['#FFAEBC', '#FBE7C6', '#B4F8C8'])\nfor index, value in enumerate(compare_acc):\n    plt.text(value, index, str(value))\nplt.title('Comparing Accuracy of the Models')\nplt.ylabel('Accuracy')\nplt.xlabel('Models')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}